---
title: Creating Golf Scores Database
author: ~
date: '2017-08-01'
slug: creating-golf-scores-database
categories: ["Golf"]
tags: ["R", "golf", "scraping", "scores", "PGA", "database", "SQL"]
thumbnailImagePosition: left
thumbnailImage: "http://res.cloudinary.com/gharv/image/upload/v1501617181/espn_golf_pic_nrgbkd.jpg"
---

The goal of this post is to create a database with all the **scores** recorded on golf tours. ESPN holds all the scorecards of players for each tournament dating back to 2001.  


We are going to start out by exploring around the ESPN website to find out how the data is stored and a way to scrape the data into R and then we are going to export this big data to SQL.  

<!--more-->

After poking around I was able to find the ESPN API URL in the picture below, which we can use to write a scraping script.  
![](http://res.cloudinary.com/gharv/image/upload/v1501615238/espn_golf_scorecard_b9a6gs.png)  


The ESPN golf tournaments increase in sequential order from 2001, so the tournament IDs start out at 1 in 2001 and continue on. At this date the last tournament is 2714 which is the [2017 RBC Canadian Open](http://www.espn.com/golf/leaderboard?tournamentId=2714).  So we just need to make a for loop going through 1 to 2714 to get all the tournaments. We want to get each players ID and their score for each hole. This will take a couple different loops but can be done. The code below can be used to create a list of all tournaments with all players and with all their scores for each hole. It will take a very long time to run because it is going over 16 years of data.


```{r, eval=FALSE}
library(rvest)
library(RCurl)
library(dplyr)

url_seed <- 'http://site.api.espn.com/apis/site/v2/sports/golf/pga/leaderboard/'
tourn_scores <- list()    # initalizing lists
tourn_players <- list()

for (i in 1:2730) {
  #tourn_url <- paste0(url_seed, 'players?event=', i)
  player_scores <- list()
  
  
  tourn_url <- paste0("http://www.espn.com/golf/leaderboard?tournamentId=", i)
  if (!RCurl::url.exists(tourn_url)) next
  tourn_html <- tourn_url %>% read_html()
  tourn_text <- tourn_url %>% read_html() %>% html_nodes('h2')
  
  if (length(tourn_text) != 3) next
  
  tourn_tbody <- tourn_html %>% html_nodes("tbody")
  
  
  tourn_players[[i]] <- sub("^.*model-(\\d+).*", "\\1", tourn_tbody)    # finds the first numbers (which is the player_id) and saves to a list
  
  if(length(tourn_players[[i]]) == 0) next    # filters out tournaments that have no data
  
  for (j in 1:length(tourn_players[[i]])) {    #tourn$leaderboard$id is each players ID

    player_url <- paste0(url_seed, i, '/playersummary?player=', tourn_players[[i]][j])
    
    if (!RCurl::url.exists(player_url)) next
    
    player <- fromJSON(player_url)
    
    player_score <- player$rounds$linescores    # returns a list of the rounds played and scores of each hole
    
    player_score_edit <- list()
    for (k in 1:length(player_score)) {    # editing list to reduce size to only necessary variables eg: score, hole num, par
      if (length(player_score[[k]]) != 0) {    # skips over rounds that were not accounted for, they will be set to NULL
        player_score_edit[[k]] <- select(player_score[[k]], value, period, par)
      }
    }

    player_scores[[tourn_players[[i]][j]]] <- player_score_edit
  }

  tourn_scores[[i]] <- player_scores

  Sys.sleep(2)
}
```

Once this is run we will have a very long list containing all the scoring data we can get our hands on.  

Unfortunately we can not just export this easily to SQL, we first need to make all this information that is contained inside multiple lists and multiple data frames. We will convert all of this into a single data frame and also make new columns to account for labeling the data with both player IDs and tournament IDs so that we can easily call the data from SQL.  

In the code below we use a couple cbinds to add the player and tournament IDs to each row. Then we add all the rows together to create a single data frame that contains all scoring data. At the end we also export this newly created data frame to MySQL using RMySQL.

```{r, eval=FALSE}
tourn_df <- data.table()
for(i in 1:2730){
  if(length(tourn_scores[[i]]) == 0) next
  tourn_df_temp2 <- data.table()
  for(j in 1:length(tourn_scores[[i]])){
    if(length(tourn_scores[[i]][[j]]) == 0) next
    tourn_df_temp <- data.table()
    tourn_df_temp <- as.data.frame(data.table::rbindlist(tourn_scores[[i]][[j]]))
    tourn_df_temp <- cbind(tourn_df_temp, pid = names(tourn_scores[[i]][j]))
    tourn_df_temp2 <- rbind(tourn_df_temp2, tourn_df_temp)
  }
  if(length(tourn_df_temp2) == 0) next
  tourn_df_temp2 <- cbind(tourn_df_temp2, tid = as.numeric(i))
  tourn_df <- bind_rows(tourn_df, tourn_df_temp2)    # using bind_rows because it will be a little quicker
}

library(RMySQL)
con_sql <- dbConnect(RMySQL::MySQL(), password = "ticklemehomo", dbname = "golf_espn") # reference : (https://www.youtube.com/watch?v=5RCPM_w3t-M)
dbWriteTable(con_sql, "Scores", tourn_df)
```

I am not going to run these two scripts because it will create a large file. The list created was just over 600 Mbs and the data frame had over 8.5 million observations. Next we will need to create another database that contains all the player and tournament names along with their IDs so we can reference them when working with SQL to making calling data easier by referencing tournaments and players by their name instead of their IDs.




